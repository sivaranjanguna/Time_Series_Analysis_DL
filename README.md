ğŸ“˜ Time Series Forecasting Using LSTM and Attention (TensorFlow)

This project focuses on multivariate time series forecasting using the S&P 500 Index (GSPC) dataset.
Two models are built and compared:

Baseline LSTM Model

Attention-based LSTM Model

Both models are trained, evaluated, and compared using RMSE and MAE metrics.
The project also includes hyperparameter tuning, attention visualization, and a fully reproducible pipeline.


ğŸ“ Project Structure
project/
â”‚
â”œâ”€â”€ data_acquisition.py
â”œâ”€â”€ preprocess.py
â”œâ”€â”€ baseline_lstm_tf.py
â”œâ”€â”€ attention_lstm_tf.py
â”œâ”€â”€ train_and_evaluate_tf.py
â”œâ”€â”€ tune_hyperparams.py
â”œâ”€â”€ visualize.py
â”‚
â”œâ”€â”€ multivariate_timeseries.csv        # Generated after running data_acquisition.py
â”œâ”€â”€ X.npy, y.npy                       # Generated after running preprocess.py
â”œâ”€â”€ scaler.pkl                         # Feature scaler
â”‚
â”œâ”€â”€ results/
â”‚      â”œâ”€â”€ baseline_forecast.png
â”‚      â”œâ”€â”€ attention_forecast.png
â”‚      â”œâ”€â”€ attention_attention_heatmap.png
â”‚      â”œâ”€â”€ baseline_forecast.png
â”‚      â”œâ”€â”€ training_curve.png
â”‚      â””â”€â”€ (others)
â”‚
â”œâ”€â”€ metrics_comparison.csv
â”œâ”€â”€ tuning_results.csv
â”‚
â””â”€â”€ README.md

ğŸ§  Project Objective

To forecast future closing prices of S&P 500 using deep learning models and evaluate if adding an attention mechanism improves predictive performance.

ğŸ“¥ 1. Data Acquisition

Run:
python data_acquisition.py


This script:

Downloads S&P 500 index data using yfinance

If internet is unavailable, generates a synthetic placeholder dataset

Saves data as multivariate_timeseries.csv

ğŸ› ï¸ 2. Preprocessing

python preprocess.py

This will:

Load the data

Remove missing values

Scale numeric features using MinMaxScaler

Create sequence windows (default 30 timesteps)

Save processed arrays X.npy and y.npy

ğŸ¤– 3. Models Included
A. Baseline LSTM Model

Single LSTM layer

Dropout

Dense output

B. Attention-Based LSTM Model

LSTM with return_sequences

Custom Attention layer

Output + attention weights

Both models use Mean Squared Error (MSE) as the loss function.

ğŸ‹ï¸ 4. Training & Evaluation

Run:
